"""
ç ”ç©¶å‘˜æ™ºèƒ½ä½“
åŒ…æ‹¬ï¼šçœ‹æ¶¨ç ”ç©¶å‘˜ã€çœ‹è·Œç ”ç©¶å‘˜ã€è¾©è®ºåè°ƒå™¨
"""
from typing import Dict, Any, List
from .llm_client import DeepSeekClient
import json

class BullResearcher:
    """çœ‹æ¶¨ç ”ç©¶å‘˜ - å¯»æ‰¾ä¹°å…¥ç†ç”±"""
    
    def __init__(self, llm_client: DeepSeekClient):
        self.llm = llm_client
        self.role = "çœ‹æ¶¨ç ”ç©¶å‘˜"
        
    def research(self, analysis_results: Dict[str, Any], stock_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»çœ‹æ¶¨è§’åº¦ç ”ç©¶"""
        print(f"\nğŸ‚ {self.role}æ­£åœ¨ç ”ç©¶...")
        
        ts_code = stock_data.get('ts_code', 'N/A')
        basic_info = stock_data.get('basic_info', {}) or {}
        
        # æ•´åˆåˆ†æç»“æœ
        context = f"""
è‚¡ç¥¨ä¿¡æ¯:
- ä»£ç : {ts_code}
- åç§°: {basic_info.get('name', 'N/A')}
- è¡Œä¸š: {basic_info.get('industry', 'N/A')}

å„åˆ†æå¸ˆè§‚ç‚¹:
æŠ€æœ¯åˆ†æ: {json.dumps(analysis_results.get('technical', {}), ensure_ascii=False, indent=2)}

åŸºæœ¬é¢åˆ†æ: {json.dumps(analysis_results.get('fundamental', {}), ensure_ascii=False, indent=2)}

æ–°é—»åˆ†æ: {json.dumps(analysis_results.get('news', {}), ensure_ascii=False, indent=2)}
"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä½çœ‹æ¶¨ç ”ç©¶å‘˜ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä»ä¹è§‚çš„è§’åº¦è¯„ä¼°æŠ•èµ„æœºä¼šã€‚

è¯·åŸºäºå„åˆ†æå¸ˆçš„è§‚ç‚¹ï¼Œä»çœ‹æ¶¨è§’åº¦è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼š
1. æ‰¾å‡ºæ‰€æœ‰åˆ©å¥½å› ç´ å’ŒæŠ•èµ„äº®ç‚¹
2. åˆ†æä¸Šæ¶¨æ½œåŠ›å’Œå‚¬åŒ–å‰‚
3. æå‡ºä¹°å…¥ç†ç”±å’Œä»·æ ¼ç›®æ ‡
4. è¯„ä¼°é£é™©ä½†ä¿æŒä¹è§‚æ€åº¦
5. ç»™å‡ºçœ‹æ¶¨ä¿¡å¿ƒæŒ‡æ•°ï¼ˆ1-10åˆ†ï¼‰

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{
    "bull_points": ["åˆ©å¥½ç‚¹1", "åˆ©å¥½ç‚¹2", ...],
    "upside_potential": "ä¸Šæ¶¨æ½œåŠ›åˆ†æ",
    "catalysts": ["å‚¬åŒ–å‰‚1", "å‚¬åŒ–å‰‚2", ...],
    "buy_thesis": "ä¹°å…¥è®ºç‚¹",
    "price_target": "ç›®æ ‡ä»·ä½åˆ†æ",
    "bull_confidence": çœ‹æ¶¨ä¿¡å¿ƒ(1-10),
    "summary": "çœ‹æ¶¨è§‚ç‚¹æ€»ç»“"
}"""
        
        response = self.llm.analyze_with_system_prompt(system_prompt, context)
        result = self.llm.parse_json_response(response)
        
        print(f"âœ… çœ‹æ¶¨ç ”ç©¶å®Œæˆï¼Œä¿¡å¿ƒæŒ‡æ•°: {result.get('bull_confidence', 'N/A')}/10")
        return result


class BearResearcher:
    """çœ‹è·Œç ”ç©¶å‘˜ - å¯»æ‰¾é£é™©å’Œå–å‡ºç†ç”±"""
    
    def __init__(self, llm_client: DeepSeekClient):
        self.llm = llm_client
        self.role = "çœ‹è·Œç ”ç©¶å‘˜"
        
    def research(self, analysis_results: Dict[str, Any], stock_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»çœ‹è·Œè§’åº¦ç ”ç©¶"""
        print(f"\nğŸ» {self.role}æ­£åœ¨ç ”ç©¶...")
        
        ts_code = stock_data.get('ts_code', 'N/A')
        basic_info = stock_data.get('basic_info', {}) or {}
        
        context = f"""
è‚¡ç¥¨ä¿¡æ¯:
- ä»£ç : {ts_code}
- åç§°: {basic_info.get('name', 'N/A')}
- è¡Œä¸š: {basic_info.get('industry', 'N/A')}

å„åˆ†æå¸ˆè§‚ç‚¹:
æŠ€æœ¯åˆ†æ: {json.dumps(analysis_results.get('technical', {}), ensure_ascii=False, indent=2)}

åŸºæœ¬é¢åˆ†æ: {json.dumps(analysis_results.get('fundamental', {}), ensure_ascii=False, indent=2)}

æ–°é—»åˆ†æ: {json.dumps(analysis_results.get('news', {}), ensure_ascii=False, indent=2)}
"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä½çœ‹è·Œç ”ç©¶å‘˜ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä»è°¨æ…çš„è§’åº¦è¯„ä¼°æŠ•èµ„é£é™©ã€‚

è¯·åŸºäºå„åˆ†æå¸ˆçš„è§‚ç‚¹ï¼Œä»çœ‹è·Œè§’åº¦è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼š
1. è¯†åˆ«æ‰€æœ‰é£é™©å› ç´ å’Œåˆ©ç©ºç‚¹
2. åˆ†æä¸‹è·Œé£é™©å’Œè´Ÿé¢å‚¬åŒ–å‰‚
3. æå‡ºå–å‡ºæˆ–è§‚æœ›ç†ç”±
4. è¯„ä¼°ä¼°å€¼æ˜¯å¦è¿‡é«˜
5. ç»™å‡ºçœ‹è·Œæ‹…å¿§æŒ‡æ•°ï¼ˆ1-10åˆ†ï¼‰

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{
    "bear_points": ["é£é™©ç‚¹1", "é£é™©ç‚¹2", ...],
    "downside_risk": "ä¸‹è·Œé£é™©åˆ†æ",
    "negative_catalysts": ["è´Ÿé¢å‚¬åŒ–å‰‚1", "è´Ÿé¢å‚¬åŒ–å‰‚2", ...],
    "sell_thesis": "å–å‡º/è§‚æœ›è®ºç‚¹",
    "valuation_concern": "ä¼°å€¼æ‹…å¿§",
    "bear_confidence": çœ‹è·Œæ‹…å¿§(1-10),
    "summary": "çœ‹è·Œè§‚ç‚¹æ€»ç»“"
}"""
        
        response = self.llm.analyze_with_system_prompt(system_prompt, context)
        result = self.llm.parse_json_response(response)
        
        print(f"âœ… çœ‹è·Œç ”ç©¶å®Œæˆï¼Œæ‹…å¿§æŒ‡æ•°: {result.get('bear_confidence', 'N/A')}/10")
        return result


class DebateCoordinator:
    """è¾©è®ºåè°ƒå™¨ - ç»„ç»‡çœ‹æ¶¨å’Œçœ‹è·Œç ”ç©¶å‘˜è¾©è®º"""
    
    def __init__(self, llm_client: DeepSeekClient):
        self.llm = llm_client
        self.role = "è¾©è®ºåè°ƒå™¨"
        
    def coordinate_debate(self, bull_view: Dict[str, Any], bear_view: Dict[str, Any], 
                         stock_data: Dict[str, Any], max_rounds: int = 2) -> Dict[str, Any]:
        """åè°ƒå¤šè½®è¾©è®º"""
        print(f"\nâš–ï¸ {self.role}æ­£åœ¨ç»„ç»‡è¾©è®º...")
        
        ts_code = stock_data.get('ts_code', 'N/A')
        basic_info = stock_data.get('basic_info', {}) or {}
        
        debate_history = []
        
        for round_num in range(1, max_rounds + 1):
            print(f"\n  ğŸ“¢ ç¬¬ {round_num}/{max_rounds} è½®è¾©è®º")
            
            # çœ‹æ¶¨æ–¹åé©³
            if round_num > 1:
                bull_rebuttal = self._get_rebuttal(
                    "çœ‹æ¶¨æ–¹", bull_view, bear_view, 
                    debate_history, stock_data
                )
                debate_history.append({"round": round_num, "speaker": "bull", "content": bull_rebuttal})
            
            # çœ‹è·Œæ–¹åé©³
            bear_rebuttal = self._get_rebuttal(
                "çœ‹è·Œæ–¹", bear_view, bull_view,
                debate_history, stock_data
            )
            debate_history.append({"round": round_num, "speaker": "bear", "content": bear_rebuttal})
        
        # æ€»ç»“è¾©è®º
        debate_summary = self._summarize_debate(bull_view, bear_view, debate_history, stock_data)
        
        print(f"âœ… è¾©è®ºå®Œæˆï¼Œå…± {max_rounds} è½®")
        
        return {
            "bull_initial": bull_view,
            "bear_initial": bear_view,
            "debate_rounds": debate_history,
            "debate_summary": debate_summary
        }
    
    def _get_rebuttal(self, side: str, own_view: Dict[str, Any], 
                     opponent_view: Dict[str, Any], history: List[Dict],
                     stock_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¾©è®ºåé©³"""
        
        context = f"""
è‚¡ç¥¨: {stock_data.get('basic_info', {}).get('name', 'N/A')} ({stock_data.get('ts_code', 'N/A')})

ä½ çš„åˆå§‹è§‚ç‚¹ï¼ˆ{side}ï¼‰:
{json.dumps(own_view, ensure_ascii=False, indent=2)}

å¯¹æ–¹è§‚ç‚¹:
{json.dumps(opponent_view, ensure_ascii=False, indent=2)}

è¾©è®ºå†å²:
{json.dumps(history, ensure_ascii=False, indent=2)}
"""
        
        system_prompt = f"""ä½ æ˜¯{side}çš„ä»£è¡¨ï¼Œåœ¨è¿›è¡ŒæŠ•èµ„è¾©è®ºã€‚

è¯·é’ˆå¯¹å¯¹æ–¹çš„è§‚ç‚¹è¿›è¡Œåé©³å’Œè¡¥å……è®ºè¯ï¼š
1. æŒ‡å‡ºå¯¹æ–¹è§‚ç‚¹çš„ä¸è¶³æˆ–åé¢‡ä¹‹å¤„
2. å¼ºåŒ–è‡ªå·±çš„æ ¸å¿ƒè®ºç‚¹
3. æä¾›æ–°çš„è¯æ®æˆ–è§’åº¦
4. ä¿æŒä¸“ä¸šå’Œå®¢è§‚

è¯·ç›´æ¥è¾“å‡ºåé©³å†…å®¹ï¼Œæ— éœ€JSONæ ¼å¼ã€‚"""
        
        rebuttal = self.llm.analyze_with_system_prompt(system_prompt, context, temperature=0.8)
        return rebuttal
    
    def _summarize_debate(self, bull_view: Dict[str, Any], bear_view: Dict[str, Any],
                         history: List[Dict], stock_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ€»ç»“è¾©è®ºç»“æœ"""
        
        context = f"""
è‚¡ç¥¨: {stock_data.get('basic_info', {}).get('name', 'N/A')} ({stock_data.get('ts_code', 'N/A')})

çœ‹æ¶¨è§‚ç‚¹:
{json.dumps(bull_view, ensure_ascii=False, indent=2)}

çœ‹è·Œè§‚ç‚¹:
{json.dumps(bear_view, ensure_ascii=False, indent=2)}

å®Œæ•´è¾©è®ºè¿‡ç¨‹:
{json.dumps(history, ensure_ascii=False, indent=2)}
"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä½å®¢è§‚çš„æŠ•èµ„é¡¾é—®ï¼Œéœ€è¦æ€»ç»“çœ‹æ¶¨å’Œçœ‹è·ŒåŒæ–¹çš„è¾©è®ºã€‚

è¯·æä¾›ä¸€ä¸ªå¹³è¡¡çš„æ€»ç»“ï¼š
1. åŒæ–¹çš„æ ¸å¿ƒè®ºç‚¹
2. æœ€æœ‰è¯´æœåŠ›çš„è§‚ç‚¹
3. å…³é”®åˆ†æ­§ç‚¹
4. ç»¼åˆé£é™©è¯„ä¼°
5. å¹³è¡¡å»ºè®®å€¾å‘ï¼ˆåçœ‹æ¶¨/ä¸­æ€§/åçœ‹è·Œï¼‰

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{
    "bull_key_points": "çœ‹æ¶¨æ ¸å¿ƒè®ºç‚¹",
    "bear_key_points": "çœ‹è·Œæ ¸å¿ƒè®ºç‚¹",
    "most_convincing": "æœ€æœ‰è¯´æœåŠ›çš„è§‚ç‚¹",
    "key_disagreements": "å…³é”®åˆ†æ­§",
    "balanced_view": "å¹³è¡¡è§‚ç‚¹",
    "recommendation_lean": "å»ºè®®å€¾å‘(åçœ‹æ¶¨/ä¸­æ€§/åçœ‹è·Œ)",
    "confidence_level": "å»ºè®®ä¿¡å¿ƒ(1-10)"
}"""
        
        response = self.llm.analyze_with_system_prompt(system_prompt, context)
        result = self.llm.parse_json_response(response)
        
        return result

